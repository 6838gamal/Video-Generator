import os
import requests
from dotenv import load_dotenv
import base64
import time
import subprocess
from gtts import gTTS

load_dotenv()

API_KEY = os.getenv("GEMINI_API_KEY")
BASE_URL = "https://generativelanguage.googleapis.com/v1beta"


# -------- Flash: ØªÙˆÙ„ÙŠØ¯ Ø¨Ø±ÙˆÙ…Ø¨Øª Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ Ø¢Ù…Ù† --------
def generate_prompt(idea):
    url = f"{BASE_URL}/models/gemini-2.5-flash:generateContent?key={API_KEY}"
    payload = {
        "contents": [{"parts": [{"text": f"Ø­ÙˆÙ„ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¥Ù„Ù‰ Ø¨Ø±ÙˆÙ…Ø¨Øª ÙÙŠØ¯ÙŠÙˆ Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ ÙˆÙ…Ù‚Ø³Ù… Ù„Ù…Ø´Ø§Ù‡Ø¯: {idea}"}]}]
    }
    r = requests.post(url, json=payload).json()
    
    candidates = r.get("candidates")
    if not candidates:
        print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ 'candidates' ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©")
        print("Full response:", r)
        return None
    
    try:
        return candidates[0]["content"]["parts"][0]["text"]
    except (IndexError, KeyError):
        print("âŒ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¨ØµÙŠØºØ© ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹Ø©:", r)
        return None


# -------- Gemini: ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± --------
def generate_image(prompt, output_file):
    url = f"{BASE_URL}/models/gemini-2.0-flash-exp:generateContent?key={API_KEY}"
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"responseModalities": ["IMAGE"]}
    }
    r = requests.post(url, json=payload).json()
    
    candidates = r.get("candidates")
    if not candidates:
        print("âŒ Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©:", r)
        return False
    
    for part in candidates[0]["content"]["parts"]:
        if "inlineData" in part:
            image_data = base64.b64decode(part["inlineData"]["data"])
            with open(output_file, "wb") as f:
                f.write(image_data)
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø©: {output_file}")
            return True
    print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©")
    return False


# -------- TTS: ØªÙˆÙ„ÙŠØ¯ ØªØ¹Ù„ÙŠÙ‚ ØµÙˆØªÙŠ --------
def generate_voice(text, output_file):
    tts = gTTS(text=text, lang='ar')
    tts.save(output_file)
    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØª: {output_file}")


# -------- FFmpeg: Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØµÙˆØª ÙÙŠ ÙÙŠØ¯ÙŠÙˆ --------
def create_video_from_images(images, audio_file, output_file):
    with open("images.txt", "w") as f:
        for img in images:
            f.write(f"file '{img}'\n")
            f.write("duration 3\n")  # Ù…Ø¯Ø© ÙƒÙ„ ØµÙˆØ±Ø© 3 Ø«ÙˆØ§Ù†ÙŠ
        f.write(f"file '{images[-1]}'\n")  # Ø¢Ø®Ø± ØµÙˆØ±Ø© Ø¨Ø¯ÙˆÙ† duration

    cmd = f"ffmpeg -y -f concat -safe 0 -i images.txt -i {audio_file} -c:v libx264 -c:a aac -shortest {output_file}"
    subprocess.run(cmd, shell=True)
    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {output_file}")


# -------- Ø§Ù„ØªØ´ØºÙŠÙ„ --------
if __name__ == "__main__":
    idea = "Ø§Ù…Ø±Ø£Ø© ÙŠÙ…Ù†ÙŠØ© ØªØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø£ØªÙ…ØªØ© ÙˆØªØ¯ÙŠØ± Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡"

    print("ğŸ¬ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¹Ø¨Ø± Flash...")
    prompt = generate_prompt(idea)
    if not prompt:
        exit("âŒ ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª. ØªØ­Ù‚Ù‚ Ù…Ù† API Key ÙˆØ§Ù„Ù…ÙˆØ¯ÙŠÙ„.")

    print("Prompt Ø§Ù„Ù†Ø§ØªØ¬:\n", prompt)

    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ù„ÙƒÙ„ Ù…Ø´Ù‡Ø¯ (Ù…Ø«Ø§Ù„ 3 Ù…Ø´Ø§Ù‡Ø¯)
    images = []
    for i in range(1, 4):
        img_file = f"scene_{i}.png"
        success = generate_image(f"{prompt} - Ù…Ø´Ù‡Ø¯ {i}", img_file)
        if success:
            images.append(img_file)

    if not images:
        exit("âŒ Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø£ÙŠ ØµÙˆØ±Ø©")

    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª
    generate_voice(prompt, "voice.mp3")

    # Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØµÙˆØª ÙÙŠ ÙÙŠØ¯ÙŠÙˆ
    create_video_from_images(images, "voice.mp3", "final_video.mp4")
